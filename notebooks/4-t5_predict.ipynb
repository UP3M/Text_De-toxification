{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/s-nlp/detox/blob/main/emnlp2021/data/test/test_10k_toxic"
      ],
      "metadata": {
        "id": "9TmQ6-CLVJk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8gnnhMEUhM8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
        "import torch\n",
        "from tqdm.auto import tqdm, trange\n",
        "import gc\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "\n",
        "def cleanup():\n",
        "    \"\"\"\n",
        "    A helpful function to clean all cached batches.\n",
        "    \"\"\"\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "#Reading the inputs\n",
        "\n",
        "# reference for test dataset https://github.com/s-nlp/detox/blob/main/emnlp2021/data/test/test_10k_toxic\n",
        "file_path = '/content/test_10k_toxic.txt'\n",
        "\n",
        "# Read the text file and split it into a list of sentences\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Split the content into a list of sentences, assuming each sentence is on a separate line\n",
        "sentences = content.split('\\n')\n",
        "\n",
        "# Remove any empty or blank lines from the list of sentences\n",
        "sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "# Print the list of sentences\n",
        "print(sentences)\n",
        "\n",
        "toxic_inputs = sentences\n",
        "#Loading the model. For the baseline we used t5_model\n",
        "\n",
        "base_model_name = 't5-small'\n",
        "model_name = '/content/drive/MyDrive/t5_base_train_10000'\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "model.to(device);\n",
        "# Paraphrasing preparation with small example\n",
        "\n",
        "def paraphrase(text, model, n=None, max_length='auto', temperature=0.0, beams=3):\n",
        "    texts = [text] if isinstance(text, str) else text\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True)['input_ids'].to(model.device)\n",
        "    if max_length == 'auto':\n",
        "        max_length = int(inputs.shape[1] * 1.2) + 10\n",
        "    result = model.generate(\n",
        "        inputs,\n",
        "        num_return_sequences=n or 1,\n",
        "        do_sample=False,\n",
        "        temperature=temperature,\n",
        "        repetition_penalty=3.0,\n",
        "        max_length=max_length,\n",
        "        bad_words_ids=[[2]],  # unk\n",
        "        num_beams=beams,\n",
        "    )\n",
        "    texts = [tokenizer.decode(r, skip_special_tokens=True) for r in result]\n",
        "    if not n and isinstance(text, str):\n",
        "        return texts[0]\n",
        "    return texts\n",
        "print(paraphrase(['you are idiot'], model, temperature=50.0, beams=10))\n",
        "\n",
        "# The inference\n",
        "para_results = []\n",
        "problematic_batch = [] #if something goes wrong you can track such bathces\n",
        "batch_size = 8\n",
        "\n",
        "for i in tqdm(range(0, len(toxic_inputs), batch_size)):\n",
        "    batch = [sentence for sentence in toxic_inputs[i:i + batch_size]]\n",
        "    try:\n",
        "        para_results.extend(paraphrase(batch, model, temperature=0.0))\n",
        "    except Exception as e:\n",
        "        print(i)\n",
        "        para_results.append(toxic_inputs[i:i + batch_size])\n",
        "# Saving the results\n",
        "\n",
        "with open('t5_result.txt', 'w') as file:\n",
        "    file.writelines([sentence+'\\n' for sentence in para_results])\n"
      ]
    }
  ]
}